class(my_vector)
my_matrix<- my_vector
matrix()
?matrix
dim(my_matrix2) <- c(4,5)
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
packageVersion("swirl")
install_from_swirl("Getting and Cleaning Data")
library("swirl")
install_from_swirl("Getting and Cleaning Data")
swirl()
bye
install_from_swirl("R programming")
install_from_swirl("R Programming")
swirl()
my_vector<-1:20
my_vector
dim(my_vector)
length(my_vector)
dim(my_vector)<-c(4,5)
dim(my_vector)
attributes(my_vector)
my_vector
class(my_vector)
my_matrix<-my_vector
?matrix
my_matrix2 <- 1:20
my_matrix2 <- matrix(c(1:20), nrow = 4, ncol = 5, dimnames = list(c("row1","row2",'row3',"row4"), c("col1","col2","col3","col4","col5")) )
matrix(my_matrix2)
skip()
identical(my_matrix,my_matrix2)
patients <- c("Bill","Gina","Kelly","Sean")
cbind(patients,my_matrix)
my_data <- data.frame(patients,my_matrix)
my_data
class(my_data)
cnames<- c("patients"."age","weight","bp","rating","test")
cnames<- c("patients","age","weight","bp","rating","test")
cnames<- c("patients","age","weight","bp","rating","test")
info()
skip()
colnames(cnames)
colnames(my_data) <- cnames
my_data
TRUE == TRUE
FALSE == TRUE
(FALSE == TRUE) == FALSE
6==7
6<=7
6<7
10<=10
5!=7
5=7
5!=7
5==7
5 == 7
skip()
FALSE & FALSE
TRUE & C(TRUE, FALSE, FALSE)
TRUE & c(TRUE, FALSE, FALSE)
TRUE && c(TRUE, FALSE, FALSE)
TRUE | c(TRUE, FALSE, FALSE)
TRUE || c(TRUE, FALSE, FALSE)
5 > 8 || 6!= 8 && 4 > 3.9
TRUE(6>4)
isTRUE( 6 > 4 )
identical('twins', 'twins')
xor(5 == 6, !FALSE)
ints <- sample(10)
ints
ints > 5
which(ints > 7)
any()
any(ints < 0)
all()
all(ints > 0)
TRUE == TRUE
(FALSE == TRUE) == FALSE
6 == 7
6 < 7
10 <= 10
5 != 7
5 == 7
!5 == 7
TRUE & TRUE
FALSE & FALSE
TRUE & c(TRUE, FALSE, FALSE)
TRUE && c(TRUE, FALSE, FALSE)
TRUE | c(TRUE, FALSE, FALSE)
TRUE || c(TRUE, FALSE, FALSE)
5>8 || 6!= 8 && 4 >3.9
dbl_var<-c(1, 2.5, 4.2)
dbl_var
is.integer(dbl_var)
int_var <- c(1L, 3L, 10L)
install.packages(c("BH", "chron", "colorspace", "curl", "data.table", "DBI", "digest", "ggplot2", "jsonlite", "openssl", "R6", "Rcpp", "reshape2", "scales", "stringi", "stringr", "tibble", "tidyr", "yaml"))
install.packages(c("BH", "chron", "colorspace", "curl", "data.table",
int_var <- c(1L,2L,10L)
remove.packages(lubridate, lib = lubridate)
remove.packages("lubridate", lib)
?remove.packages
remove.packages(lubridate)
install.packages("xmlparsedata")
library(xmlparsedata)
install.packages("XML")
library("XML")
fileUrl <-"http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens"
doc<- htmlTreeParse(fileUrl,useInternalNodes = TRUE)
scores <- xpathSApply(doc,"//lil@class='score']",xmlValue)
scores <- xpathSApply(doc,".//lil@class="score""]",xmlValue)
scores <- xpathSApply(doc,".//lil@class="score"]",xmlValue)
scores <- xpathSApply(doc,"...//lil@class='score']",xmlValue)
fileUrl<- "http://www.w3schools.com/ xml/simple.xml"
doc<- xmlTreeParse(fileUrl, useInternal=TRUE)
doc<- xmlTreeParse(fileUrl, useInternalNodes = TRUE)
rootNode<- xmlRoot(doc)
xmlName(rootNode)
fileUrl<- "http://www.w3schools.com/xml/simple.xml"
doc<-xmlTreeParse(fileUrl,useInternalNodes = TRUE)
rootNode<-xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode[[1]]
rootNode[[3]]
rootNode[[1]][[2]]
rootNode[[1]][[1]]
xmlSApply(rootNode,xmlValue)
xpathSApply(rootNode,"//name",xmlValue)
xpathSApply(rootNode,"//price",xmlValue)
fileUrl<-"http://www.espn.com/nfl/team/_/name/bal/baltimore-ravens"
doc<-htmlTreeParse(fileUrl,useInternalNodes = TRUE)
scores<-xpathSApply(doc,"//li[@class='score']",xmlValue)
teams<-xpathSApply(doc,"//li[@class='team-name']",xmlValue)
scores
teams
install.packages("jsonlite")
library(jsonlite)
jsonData<-fromJSON("https://api.github.com/users/jtleek/repos")
names(jsonData)
names(jsonData$owner)
jsonData$owner$id
jsonData$owner$type
jsonData$owner$login
myjson<-toJSON(iris,pretty = TRUE)
cat(myjson)
iris2 <- fromJSON(myjson)
head(iris2)
install.packages("data.table")
library(data.table)
DF = data.frame(x=rnorm(9), y= rep(c("a","b","c")),each=3),z=rnorm(9))
DF <- data.frame(x=rnorm(9),y= rep(c("a","b","c"),each=3),z=rnorm(9))
head(DF)
DT <- data.table(x=rnorm(9),y= rep(c("a","b","c"),each=3),z=rnorm(9))
head(DT)
table()
head(DT,n=3)
head(DF,n=4)
DT[,m:={tmp<-(x+z);log2(tmp+5)}]
DT
DT[,a:=x>0]
DT
DT[,b=mean(x+w),by=a]
DT[,b:=mean(x+w),by=a]
DT1<- data.table(x=c('a','a','b','dt1'),y=1:4)
DT2<- data.table(x=c('a','b','dt2'),z=5:7)
setkey(DT1,x);setkey(DT2,x)
merge(DT1,DT2)
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
library("swirl")
rm(list = ls())
swirl()
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf<-read.csv("//path2csv",stringsAsFactors = FALSE)
mydf<-read.csv(path2csv,header = true,stringsAsFactors = FALSE)
skip()
dim(mydf)
head()
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
print(tbl_df)
print()
print("tbl_df")
cran
?select
rm(list = ls())
install.packages("caret",dependencies=c("Depends", "Suggests"))
library(caret)
install.packages("lattice")
install.packages("lattice")
library(lattice)
install.packages("ggplot2")
library(ggplot2)
data("iris")
dataset <- iris
filename <- "C:/Users/Gunjan/Desktop/coursera/datasets/iris.csv"
dataset <- read.csv(filename,header = FALSE)
colnames(dataset) <- c(""Sepal.Length","Sepal.Width","Petal.Length","Petal.Width","Species")
colnames(dataset) <- c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width","Species")
validation_index <- createDataPartition(dataset$Species, p=0.80, list=FALSE)
install.packages("munsell")
install.packages("munsell")
library(munsell)
validation_index <- createDataPartition(dataset$Species, p=0.80, list=FALSE)
install.packages("caret",dependencies=c("Depends","Imports",Suggests"))
install.packages("caret")
install.packages("caret", dependencies=c("Depends", "Suggests"))
library(caret)
validation_index <- createDataPartition(dataset$Species, p=0.80, list=FALSE)
validation <- dataset[-validation_index,]
dataset <- dataset[validation_index,]
dim(dataset)
sapply(dataset,class)
head(dataset)
levels(dataset$species)
levels(dataset$Species)
percentage <- prop.table(table(dataset$Species)) * 100
cbind(freq=table(dataset$Species), percentage=percentage)
summary(dataset)
x <- dataset[,1:4]
y <- dataset[,5]
par(mfrow=c(1,4))
par(mfrow=c(1,4))
for(i in 1:4) {
boxplot(x[,i], main=names(iris)[i])
}
par(mfrow=c(1,4))
for(i in 1:4) {
boxplot(x[,i], main=names(iris)[i])
}
plot(y)
par(mfrow=c(1,4))
for(i in 1:4) {
boxplot(x[,i], main=names(iris)[i])
}
data(mtcars)
str(mtcars)
head(mtcars)
fivenum(mtcars$mpg)
hist(mtcars$mpg,breaks = 10)
IQR(mtcars$mpg)
boxplot(mtcars$mpg)
mtcars<-edit(mtcars)
boxplot(mtcars$mpg)
boxplot(mtcars$mpg ~ mtcars$cyl)
boxplot(mtcars$mpg ~ mtcars$cyl,main="mpg")
boxplot(mtcars$mpg ~ mtcars$cyl,main="mpg",xlab="cyl", ylab="mpg")
boxplot(mtcars$mpg ~ mtcars$cyl, main="mpg", xlab="cyl", ylab="mpg", col="red")
mtcars<- edit(mtcars)
boxplot(mtcars$mpg ~ mtcars$cyl, main="My first plot", xlab="cyl", ylab="mpg", col="purple")
par(bg="pink")
colors()
boxplot(mtcars$mpg ~ mtcars$cyl, main="My first plot", xlab="cyl", ylab="mpg", col="pink")
boxplot(mtcars$mpg ~ mtcars$cyl, main="My first plot", xlab="cyl", ylab="mpg", col="purple")
boxplot(mtcars$mpg ~ mtcars$cyl, main="My first plot", xlab="cyl", ylab="mpg", col="purple")
library(lattice)
bwplot(mtcars$mpg,mtcars$cyl,main="MY 2nd Plot", xlab = "mpg",ylab="cyl",col="green")
bwplot(mtcars$mpg,mtcars$cyl,main="My second Plot", xlab = "mpg",ylab="cyl",col="green", pch=5)
bwplot(mtcars$mpg,mtcars$cyl,main="My second Plot", xlab = "mpg",ylab="cyl",col="green", pch=2)
par(bg="yellow")
bwplot(mtcars$mpg,mtcars$cyl,main="My second Plot", xlab = "mpg",ylab="cyl",col="green", pch=2)
xyplot(mtcars$mpg ~ mtcars$cyl)
xyplot(mtcars$mpg ~ mtcars$cyl,col="red",pch=10)
library(ggplot2)
qplot(mtcars$mpg,mtcars$cyl,data = mtcars , geom = "boxplot")
qplot(mtcars$mpg,mtcars$cyl,data = mtcars, geom = "boxplot")
library(Hmisc)
install.packages("ggplot2")
library(ggplot2)
install.packages("ggplot2")
qplot(mtcars$mpg, mtcars$cyl,data = mtcars,geom = "boxplot")
exit
ls()
rm(list = ls())
install.packages("swirl")
install.packages("swirl")
package_version("swirl")
packageVersion("swirl")
library(swirl)
install_from_swirl("Exploratory Data Analysis")
swirl()
library(swirl)
ls()
install.packages("swirl")
rm(list = ls())
ls()
ls()
rm(list = ls())
install.packages("swirl")
install.packages("swirl")
library(swirl)
install_from_swirl("Exploratory Data Analysis")
swirl()
rm(list = ls())
#Downloading and unzipping dataset
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl,destfile="./data/Dataset.zip")
# Unzip dataSet to /data directory
unzip(zipfile="./data/Dataset.zip",exdir="./data")
# Loading the training datasets
train <- read.table("UCI HAR Dataset/train/X_train.txt")
trainActivities <- read.table("UCI HAR Dataset/train/Y_train.txt")
trainSubjects <- read.table("UCI HAR Dataset/train/subject_train.txt")
# Loading the testing datasets
test <- read.table("UCI HAR Dataset/test/X_test.txt")
testActivities <- read.table("UCI HAR Dataset/test/Y_test.txt")
testSubjects <- read.table("UCI HAR Dataset/test/subject_test.txt")
# Loading feature vector:
features <- read.table('./data/UCI HAR Dataset/features.txt')
# Loading activity labels:
activityLabels = read.table('./data/UCI HAR Dataset/activity_labels.txt')
##Assigning column names:
colnames(x_train) <- features[,2]
colnames(y_train) <-"activityId"
colnames(subject_train) <- "subjectId"
colnames(x_test) <- features[,2]
colnames(y_test) <- "activityId"
colnames(subject_test) <- "subjectId"
colnames(activityLabels) <- c('activityId','activityType')
# merge datasets and add labels
allDatatrain <- cbind(train,trainSubjects,trainActivities)
allDatatest <- cbind(test,testSubjects,testActivities)
allData<- rbind(allDatatrain,allDatatest)
#Extraction of the measurements on the mean and standard deviation for each measurement
##Reading column names:
colNames <- colnames(allData)
##Create vector for defining ID, mean and standard deviation:
meanAndstd <- (grepl("activityId" , colNames) |
grepl("subjectId" , colNames)  |
grepl("mean.." , colNames)     |
grepl("std.." , colNames)
)
##Making nessesary subset from allData:
allMeanAndStd <- allData[ , meanAndstd  == TRUE]
#Using descriptive activity names to name the activities in the data set:
#allDataActivityNames <- merge(allMeanAndStd, activityLabels,
#                              by='activityId',all.x=TRUE)
#Creating a second, independent tidy data set with the average of each variable for each activity and each subject:
## Making second tidy data set
secTidySet <- aggregate(. ~subjectId + activityId, allDataActivityNames, mean)
secTidySet <- secTidySet[order(secTidySet$subjectId, secTidySet$activityId),]
##Writing second tidy data set in txt file
write.table(secTidySet, "secTidySet.txt", row.name=FALSE)
#Downloading and unzipping dataset
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl,destfile="./data/Dataset.zip")
# Unzip dataSet to /data directory
unzip(zipfile="./data/Dataset.zip",exdir="./data")
# Loading the training datasets
train <- read.table("UCI HAR Dataset/train/X_train.txt")
trainActivities <- read.table("UCI HAR Dataset/train/Y_train.txt")
trainSubjects <- read.table("UCI HAR Dataset/train/subject_train.txt")
# Loading the testing datasets
test <- read.table("UCI HAR Dataset/test/X_test.txt")
testActivities <- read.table("UCI HAR Dataset/test/Y_test.txt")
testSubjects <- read.table("UCI HAR Dataset/test/subject_test.txt")
# Loading feature vector:
features <- read.table('./data/UCI HAR Dataset/features.txt')
# Loading activity labels:
activityLabels = read.table('./data/UCI HAR Dataset/activity_labels.txt')
##Assigning column names:
colnames(x_train) <- features[,2]
colnames(y_train) <-"activityId"
colnames(subject_train) <- "subjectId"
colnames(x_test) <- features[,2]
colnames(y_test) <- "activityId"
colnames(subject_test) <- "subjectId"
colnames(activityLabels) <- c('activityId','activityType')
# merge datasets and add labels
allDatatrain <- cbind(train,trainSubjects,trainActivities)
allDatatest <- cbind(test,testSubjects,testActivities)
allData<- rbind(allDatatrain,allDatatest)
#Extraction of the measurements on the mean and standard deviation for each measurement
##Reading column names:
colNames <- colnames(allData)
##Create vector for defining ID, mean and standard deviation:
meanAndstd <- (grepl("activityId" , colNames) |
grepl("subjectId" , colNames)  |
grepl("mean.." , colNames)     |
grepl("std.." , colNames)
)
##Making nessesary subset from allData:
allMeanAndStd <- allData[ , meanAndstd  == TRUE]
#Using descriptive activity names to name the activities in the data set:
#allDataActivityNames <- merge(allMeanAndStd, activityLabels,
#                              by='activityId',all.x=TRUE)
#Creating a second, independent tidy data set with the average of each variable for each activity and each subject:
## Making second tidy data set
secTidySet <- aggregate(. ~subjectId + activityId, allDataActivityNames, mean)
#secTidySet <- secTidySet[order(secTidySet$subjectId, secTidySet$activityId),]
##Writing second tidy data set in txt file
#write.table(secTidySet, "secTidySet.txt", row.name=FALSE)
#Downloading and unzipping dataset
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl,destfile="./data/Dataset.zip")
# Unzip dataSet to /data directory
unzip(zipfile="./data/Dataset.zip",exdir="./data")
# Loading the training datasets
train <- read.table("UCI HAR Dataset/train/X_train.txt")
trainActivities <- read.table("UCI HAR Dataset/train/Y_train.txt")
trainSubjects <- read.table("UCI HAR Dataset/train/subject_train.txt")
# Loading the testing datasets
test <- read.table("UCI HAR Dataset/test/X_test.txt")
testActivities <- read.table("UCI HAR Dataset/test/Y_test.txt")
testSubjects <- read.table("UCI HAR Dataset/test/subject_test.txt")
# Loading feature vector:
features <- read.table('./data/UCI HAR Dataset/features.txt')
# Loading activity labels:
activityLabels = read.table('./data/UCI HAR Dataset/activity_labels.txt')
##Assigning column names:
colnames(x_train) <- features[,2]
colnames(y_train) <-"activityId"
colnames(subject_train) <- "subjectId"
colnames(x_test) <- features[,2]
colnames(y_test) <- "activityId"
colnames(subject_test) <- "subjectId"
colnames(activityLabels) <- c('activityId','activityType')
# merge datasets and add labels
allDatatrain <- cbind(train,trainSubjects,trainActivities)
allDatatest <- cbind(test,testSubjects,testActivities)
allData<- rbind(allDatatrain,allDatatest)
#Extraction of the measurements on the mean and standard deviation for each measurement
##Reading column names:
colNames <- colnames(allData)
##Create vector for defining ID, mean and standard deviation:
meanAndstd <- (grepl("activityId" , colNames) |
grepl("subjectId" , colNames)  |
grepl("mean.." , colNames)     |
grepl("std.." , colNames)
)
##Making nessesary subset from allData:
allMeanAndStd <- allData[ , meanAndstd  == TRUE]
#Using descriptive activity names to name the activities in the data set:
#allDataActivityNames <- merge(allMeanAndStd, activityLabels,
#                              by='activityId',all.x=TRUE)
#Creating a second, independent tidy data set with the average of each variable for each activity and each subject:
## Making second tidy data set
##secTidySet <- aggregate(. ~subjectId + activityId, allDataActivityNames, mean)
#secTidySet <- secTidySet[order(secTidySet$subjectId, secTidySet$activityId),]
##Writing second tidy data set in txt file
#write.table(secTidySet, "secTidySet.txt", row.name=FALSE)
rm(list = ls())
getwd()
setwd("C:/Users/Gunjan/Desktop/coursera/Getting and Cleaning Data assignment")
getwd()
library(plyr)
# Step 1
# Merge the training and test sets to create one data set
###############################################################################
x_train <- read.table("train/X_train.txt")
y_train <- read.table("train/y_train.txt")
subject_train <- read.table("train/subject_train.txt")
x_test <- read.table("test/X_test.txt")
y_test <- read.table("test/y_test.txt")
subject_test <- read.table("test/subject_test.txt")
# create 'x' data set
x_data <- rbind(x_train, x_test)
# create 'y' data set
y_data <- rbind(y_train, y_test)
# create 'subject' data set
subject_data <- rbind(subject_train, subject_test)
# Step 2
# Extract only the measurements on the mean and standard deviation for each measurement
###############################################################################
features <- read.table("features.txt")
# get only columns with mean() or std() in their names
mean_and_std_features <- grep("-(mean|std)\\(\\)", features[, 2])
# subset the desired columns
x_data <- x_data[, mean_and_std_features]
# correct the column names
names(x_data) <- features[mean_and_std_features, 2]
# Step 3
# Use descriptive activity names to name the activities in the data set
###############################################################################
activities <- read.table("activity_labels.txt")
# update values with correct activity names
y_data[, 1] <- activities[y_data[, 1], 2]
# correct column name
names(y_data) <- "activity"
# Step 4
# Appropriately label the data set with descriptive variable names
###############################################################################
# correct column name
names(subject_data) <- "subject"
# bind all the data in a single data set
all_data <- cbind(x_data, y_data, subject_data)
# Step 5
# Create a second, independent tidy data set with the average of each variable
# for each activity and each subject
###############################################################################
# 66 <- 68 columns but last two (activity & subject)
averages_data <- ddply(all_data, .(subject, activity), function(x) colMeans(x[, 1:66]))
write.table(averages_data, "averages_data.txt", row.name=FALSE)
